{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.array(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=8).T)\n",
    "    chroma = np.array(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T)\n",
    "    mel = np.array(librosa.feature.melspectrogram(X, sr=sample_rate).T)\n",
    "    contrast = np.array(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T)\n",
    "    tonnetz = np.array(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_audio_files(parent_dir,sub_dirs,file_ext='*.wav'):\n",
    "    ignored = 0\n",
    "    features, labels, name = np.empty((0,161)), np.empty(0), np.empty(0)\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        print(sub_dir)\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            try:\n",
    "                mfccs, chroma, mel, contrast, tonnetz = extract_features(fn)\n",
    "                ext_features = np.hstack([mfccs, chroma, mel, contrast, tonnetz])\n",
    "                features = np.vstack([features,ext_features])\n",
    "                l = [fn.split('-')[1]] * (mfccs.shape[0])\n",
    "                labels = np.append(labels, l)\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                raise\n",
    "            except:\n",
    "                ignored += 1\n",
    "    print (\"Ignored files: \", ignored)\n",
    "    return np.array(features), np.array(labels, dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels found!\n"
     ]
    }
   ],
   "source": [
    "parent_dir = 'C:/Users/rano4/Desktop/5thyear/graduationproject/Project/UrbanSound8K/audio'\n",
    "\n",
    "sub_dirs = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'fold6', 'fold7', 'fold8', 'fold9', 'fold10']\n",
    "#sub_dirs = ['fold1']\n",
    "\n",
    "try:\n",
    "    labels = np.load('labels.npy')\n",
    "    features = np.load('features.npy')\n",
    "    print(\"Features and labels found!\")\n",
    "except:\n",
    "    print(\"Extracting features...\")\n",
    "    features, labels = parse_audio_files(parent_dir,sub_dirs)\n",
    "    with open('features.npy', 'wb') as f1:\n",
    "            np.save(f1,features)\n",
    "    with open('labels.npy', 'wb') as f2:\n",
    "            np.save(f2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting Data!\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting Data!\")\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalization data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"normalization data\")\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"fit_params.npy\", \"wb\") as f3:\n",
    "    np.save(f3, train_x)\n",
    "train_x = sc.transform(train_x)\n",
    "test_x = sc.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#must use decision_function_shape='ovo' when it's multi classification problem\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(train_x, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91336609575710392"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_x, test_y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91995370515186592"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(train_x, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-d5c09599f417>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-d5c09599f417>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    dec = clf.decision_function([161,:])\u001b[0m\n\u001b[1;37m                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ed91ab52786e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dec' is not defined"
     ]
    }
   ],
   "source": [
    "dec.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.decision_function_shape = \"ovr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec = clf.decision_function([[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec.shape[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
